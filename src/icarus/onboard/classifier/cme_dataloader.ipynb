{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf184f-2fc6-4bdc-9af7-3563fb281c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import astropy.io.fits as fits\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b7e48-7b1f-40ed-abcc-05ab074ba273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std_from_histogram(bin_edges, bin_counts):\n",
    "    # Calculate midpoints of each bin\n",
    "    bin_midpoints = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    \n",
    "    # Calculate weighted sum and total count\n",
    "    weighted_sum = np.sum(bin_midpoints * bin_counts)\n",
    "    total_count = np.sum(bin_counts)\n",
    "    \n",
    "    # Calculate mean\n",
    "    mean = weighted_sum / total_count\n",
    "    \n",
    "    # Calculate weighted squared deviation from mean\n",
    "    weighted_squared_deviation = np.sum(bin_counts * (bin_midpoints - mean)**2)\n",
    "    \n",
    "    # Calculate weighted standard deviation\n",
    "    std = np.sqrt(weighted_squared_deviation / total_count)\n",
    "    \n",
    "    return mean, std\n",
    "\n",
    "def get_dataset_counts(dataset):\n",
    "    \n",
    "    bit_depth = ds[0].flatten()[0].nbytes\n",
    "    n_vals = 2**(8*bit_depth)\n",
    "    counts = np.zeros(n_vals, dtype=np.uint64)\n",
    "\n",
    "    for d in tqdm(dataset):\n",
    "        counts += np.bincount(d.flatten(), minlength=n_vals).astype(np.uint64)\n",
    "\n",
    "    return counts\n",
    "    \n",
    "\"\"\"\n",
    "counts = get_dataset_mean_std(ds)\n",
    "hist_edges = np.arange(len(counts) + 1)\n",
    "hist_counts = counts\n",
    "\n",
    "# Compute mean and standard deviation from the histogram\n",
    "mean, std = compute_mean_std_from_histogram(hist_edges, hist_counts)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55691686",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833dfae-d80c-4218-8100-25fb1fc864c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_within_time_range(events, image_paths):\n",
    "    selected_images = []\n",
    "\n",
    "    # Organize image paths by date for efficient checking\n",
    "    image_paths_by_date = {}\n",
    "    for image_path in image_paths:\n",
    "        image_date = datetime.strptime(os.path.basename(image_path).split('_')[0], '%Y%m%d').date()\n",
    "        image_paths_by_date.setdefault(image_date, []).append(image_path)\n",
    "\n",
    "    for event in events:\n",
    "\n",
    "        if not event['visible']:\n",
    "            continue\n",
    "\n",
    "        if event['faint']:\n",
    "            continue\n",
    "        \n",
    "        event_start_time = datetime.strptime(event['datetime'], '%Y/%m/%d %H:%M')\n",
    "        event_stop_time = datetime.strptime(event['event_stop_time'], '%Y%m%d_%H%M%S')\n",
    "        event_date = event_start_time.date()\n",
    "        \n",
    "        # Check images within the event's date\n",
    "        if event_date in image_paths_by_date:\n",
    "\n",
    "            paths = image_paths_by_date[event_date]\n",
    "\n",
    "            next_day = event_date + timedelta(days=1)\n",
    "            if next_day in image_paths_by_date:\n",
    "                paths.extend(image_paths_by_date[next_day])\n",
    "            \n",
    "            for image_path in paths:\n",
    "                image_timestamp = datetime.strptime('_'.join(os.path.basename(image_path).split('_')[:2]), '%Y%m%d_%H%M%S')\n",
    "                if event_start_time <= image_timestamp <= event_stop_time:\n",
    "                    selected_images.append(image_path)\n",
    "\n",
    "    return selected_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e01da-63de-4071-b9d8-440e1c6fa7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMEDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root, events = [], pol='all', size=512):\n",
    "        self.cache_dir = os.path.join(root, '.cache')\n",
    "        os.makedirs(self.cache_dir, exist_ok=True)\n",
    "        \n",
    "        self.events = events\n",
    "        self.stereo_a = glob(os.path.join(root, \"201402*\", \"cor1\", \"stereo_a\", \"*\", \"*.fts\"))\n",
    "        self.stereo_b = glob(os.path.join(root, \"201402*\", \"cor1\", \"stereo_b\", \"*\", \"*.fts\"))\n",
    "        self.pol = pol\n",
    "\n",
    "        self.images = []\n",
    "\n",
    "        if pol == 'all':\n",
    "            self.mean = 2691.3037070368546 \n",
    "            self.std = 2579.566574917962\n",
    "            self.images.extend([im for im in self.stereo_a if os.path.basename(os.path.dirname(im)) != '1001.0'])\n",
    "            self.images.extend([im for im in self.stereo_b if os.path.basename(os.path.dirname(im)) != '1001.0'])\n",
    "        elif pol == 'sum':\n",
    "            self.images.extend([im for im in self.stereo_a if 'n4' in im])\n",
    "            self.images.extend([im for im in self.stereo_b if 'n4' in im])\n",
    "            self.mean = 3658.224788149089\n",
    "            self.std = 3399.0258091444553\n",
    "        else:\n",
    "            self.mean = 2691.3037070368546 \n",
    "            self.std = 2579.566574917962\n",
    "\n",
    "            self.images.extend([im for im in self.stereo_a if os.path.basename(os.path.dirname(im)) == pol])\n",
    "            self.images.extend([im for im in self.stereo_b if os.path.basename(os.path.dirname(im)) == pol])\n",
    "\n",
    "        # filter size\n",
    "        for image in self.images:\n",
    "            if fits.getdata(image).shape != (size,size):\n",
    "                print(f\"Removing {image}\")\n",
    "                self.images.remove(image)\n",
    "\n",
    "        self.images = sorted(self.images)\n",
    "        #self.images_for_date = defaultdict(lambda: defaultdict(list))\n",
    "        self.images_for_date = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "        self.dates = set()\n",
    "        \n",
    "        for image_path in self.images:\n",
    "            image_date = self._image_date(image_path)\n",
    "            sat, angle = self._image_info(image_path)\n",
    "\n",
    "            self.images_for_date[image_date][sat][angle].append(image_path)\n",
    "            self.dates.add(image_date)\n",
    "            \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),                   # Convert image to PyTorch tensor\n",
    "            transforms.Normalize(mean=self.mean, std=self.std) # Normalize using mean and std\n",
    "        ])\n",
    "\n",
    "        self._get_labels()\n",
    "        self._gen_background()\n",
    "\n",
    "    def _image_date(self, image):\n",
    "        return datetime.strptime(os.path.basename(image).split('_')[0], '%Y%m%d').date()\n",
    "\n",
    "    def _image_info(self, image_path):\n",
    "        if 'stereo_a' in image_path: sat = 'stereo_a'\n",
    "        elif 'stereo_b' in image_path: sat = 'stereo_b'\n",
    "        if \"0.0\" in image_path: angle = 0\n",
    "        elif \"120.0\" in image_path: angle = 120\n",
    "        elif \"240.0\" in image_path: angle = 240\n",
    "        elif \"1001.0\" in image_path: angle = 1001\n",
    "\n",
    "        return sat, angle\n",
    "\n",
    "    def _get_labels(self):\n",
    "        self.positive_labels = set(extract_images_within_time_range(self.events['stereo_a'], self.stereo_a))\n",
    "        self.positive_labels |= set(extract_images_within_time_range(self.events['stereo_b'], self.stereo_b))\n",
    "        self.cme_images = set([im for im in self.images if im in self.positive_labels])\n",
    "\n",
    "    def _gen_background(self, filter_cme=False):\n",
    "\n",
    "        cache_root = os.path.join(self.cache_dir, \"background\")\n",
    "        os.makedirs(cache_root, exist_ok=True)\n",
    "        print(\"Cache:\", cache_root)\n",
    "\n",
    "        self.background = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "        \n",
    "        #self.background = {}\n",
    "        for date in tqdm(sorted(list(self.dates))):\n",
    "            image_date = date - timedelta(days=1)\n",
    "            date_string = date.strftime(\"%Y%m%d\")\n",
    "            \n",
    "            #if date not in self.background:\n",
    "            #    self.background[date] = {}\n",
    "            \n",
    "            if image_date not in self.images_for_date:\n",
    "                image_date = date\n",
    "\n",
    "            # TODO add polar angle if \"all\": sat, angle = self._image_info(image_path) to replace self.pol\n",
    "\n",
    "            for sat in ['stereo_a', 'stereo_b']:\n",
    "                cache_path = os.path.join(cache_root, f\"{date_string}_{sat}_{self.pol}.npy\")\n",
    "    \n",
    "                if os.path.exists(cache_path):\n",
    "                    self.background[date][sat][self.pol] = np.load(cache_path)\n",
    "                else:\n",
    "                    imgs = self.images_for_date[image_date][sat][self.pol]\n",
    "\n",
    "                    if filter_cme:\n",
    "                        imgs = np.array([fits.getdata(im) for im in imgs if im not in self.cme_images])\n",
    "                    else:\n",
    "                        imgs = np.array([fits.getdata(im) for im in imgs])\n",
    "                    \n",
    "                    self.background[date][sat][self.pol] = np.median(imgs, axis=0)\n",
    "                    np.save(cache_path, self.background[date][sat][self.pol])\n",
    "\n",
    "    def _get_background(self, img_path):\n",
    "        \"\"\"\n",
    "        given image path, retrieve correct background from dict\n",
    "        TODO: expand to polar angle\n",
    "        \"\"\"\n",
    "        image_date = self._image_date(image_path)\n",
    "        sat, angle = self._image_info(image_path)\n",
    "        bg = self.background[image_date][sat][angle]\n",
    "\n",
    "        #if 'stereo_a' in image_path:\n",
    "        #    bg = self.background[image_date]['stereo_a']\n",
    "        #elif 'stereo_b' in image_path:\n",
    "        #    bg = self.background[image_date]['stereo_b']\n",
    "        #else:\n",
    "        #    print(\"Error retrieving background for\", img_path)\n",
    "\n",
    "        return bg\n",
    "\n",
    "    def _get_difference_image(self, i):\n",
    "        \"\"\"\n",
    "        TODO: ensure differencing over same sat, same polar with i-1\n",
    "        \"\"\"\n",
    "        # read raw images for current and previous\n",
    "        # fits.getdata(ds.images_for_date[date]['stereo_b'][idx])\n",
    "        raw_img_i = fits.getdata(self.images[i]).astype(np.float32)\n",
    "        raw_img_j = fits.getdata(self.images[i-1]).astype(np.float32)\n",
    "\n",
    "        # get background for current\n",
    "        bg_i = self._get_background(self.images[i])\n",
    "\n",
    "        # get difference image with subtracted background\n",
    "        diff_img = (raw_img_i - bg_i) - (raw_img_j - bg_i)\n",
    "\n",
    "        return diff_img\n",
    "\n",
    "                                     \n",
    "    def __getitem__(self, i):\n",
    "        data  = self._get_difference_image(i)\n",
    "        label = int(self.images[i] in self.cme_images)\n",
    "        \n",
    "        return self.transform(data), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b67672-d73f-48dd-a12b-daafc2d29c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('events_201402.json', 'r') as fp:\n",
    "    events = json.load(fp)\n",
    "\n",
    "#events['stereo_a'] = [events['stereo_a'][10]]\n",
    "#events['stereo_b'] = [events['stereo_b'][10]]\n",
    "\n",
    "#ds = CMEDataset(root=\"/media/josh/josh_tuf_a/data/fdl/2023/onboard\", pol='0.0', events=events)\n",
    "ds = CMEDataset(root=\"/mnt/onboard_data/classifier\", pol='0.0', events=events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c74b2dd-81a4-4e5f-a8cc-6a85d9ef28a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds.cme_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f1ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.images[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a480e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.images[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6080987-43df-4479-9c3b-45d440ea9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a08201",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.images_for_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f021b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c1ba07",
   "metadata": {},
   "source": [
    "## Check mean std for normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72af0bfd",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* double check and update for when background is removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f810655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std_from_histogram(bin_edges, bin_counts):\n",
    "    # Calculate midpoints of each bin\n",
    "    bin_midpoints = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    \n",
    "    # Calculate weighted sum and total count\n",
    "    weighted_sum = np.sum(bin_midpoints * bin_counts)\n",
    "    total_count = np.sum(bin_counts)\n",
    "    \n",
    "    # Calculate mean\n",
    "    mean = weighted_sum / total_count\n",
    "    \n",
    "    # Calculate weighted squared deviation from mean\n",
    "    weighted_squared_deviation = np.sum(bin_counts * (bin_midpoints - mean)**2)\n",
    "    \n",
    "    # Calculate weighted standard deviation\n",
    "    std = np.sqrt(weighted_squared_deviation / total_count)\n",
    "    \n",
    "    return mean, std\n",
    "\n",
    "def get_dataset_counts(dataset):\n",
    "    \n",
    "    #bit_depth = ds[0].flatten()[0].nbytes\n",
    "    bit_depth = ds[0][0].flatten()[0].numpy().nbytes\n",
    "    n_vals = 2**(8*bit_depth)\n",
    "    counts = np.zeros(n_vals, dtype=np.uint64)\n",
    "\n",
    "    for d in tqdm(dataset):\n",
    "        #counts += np.bincount(d.flatten(), minlength=n_vals).astype(np.uint64)\n",
    "        counts += np.bincount(d[0].flatten(), minlength=n_vals).astype(np.uint64)\n",
    "\n",
    "    return counts\n",
    "\n",
    "def get_dataloader_meanstd(ds):\n",
    "    counts = get_dataset_counts(ds)\n",
    "    hist_edges = np.arange(len(counts) + 1)\n",
    "    hist_counts = counts\n",
    "\n",
    "    # Compute mean and standard deviation from the histogram\n",
    "    mean, std = compute_mean_std_from_histogram(hist_edges, hist_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d909dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds = CMEDataset(root=\"/mnt/onboard_data/classifier\", pol='0.0', events=events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78dc0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0] # for now fails if background given as __get_item fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be wrong\n",
    "get_dataloader_meanstd(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9e512",
   "metadata": {},
   "source": [
    "## Check CME images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c1c692-25cf-49a9-8cb5-a3f7498be517",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime(2014, 2, 25).date()\n",
    "bg = ds.background[date]['stereo_b']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(bg)\n",
    "plt.colorbar(location='bottom')\n",
    "\n",
    "plt.subplot(122)\n",
    "_ = plt.hist(bg.flatten(), bins=256)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c8354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b563b-1752-41a1-91e0-01c7e8415910",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "img_curr = fits.getdata(ds.images_for_date[date]['stereo_b'][idx])\n",
    "img_prev = fits.getdata(ds.images_for_date[date]['stereo_b'][idx-1])\n",
    "\n",
    "img = (img_curr - bg) - (img_prev - bg)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.colorbar(location='bottom')\n",
    "\n",
    "plt.subplot(122)\n",
    "_ = plt.hist(img.flatten(), bins=256)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5981e4ad-ac0e-493f-a863-bf90331a0c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36093c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sunpy.map.maputils import all_coordinates_from_map\n",
    "from sunpy.map import Map\n",
    "from astropy.coordinates import SkyCoord\n",
    "from matplotlib.colors import LogNorm, Normalize, PowerNorm\n",
    "from rich.progress import Progress\n",
    "from sunpy.map import Map\n",
    "import astropy.units as u\n",
    "\n",
    "def generate_image(img_fname, ref_map, vmin=0, vmax=20):\n",
    "    \"\"\"\n",
    "    for single image\n",
    "    \"\"\"\n",
    "    m = Map(img_fname)\n",
    "\n",
    "    pixel_coords = all_coordinates_from_map(m)\n",
    "    solar_center = SkyCoord(0 * u.deg, 0 * u.deg, frame=m.coordinate_frame)\n",
    "    pixel_radii = np.sqrt(\n",
    "        (pixel_coords.Tx - solar_center.Tx) ** 2\n",
    "        + (pixel_coords.Ty - solar_center.Ty) ** 2\n",
    "    )\n",
    "    # r2 masking\n",
    "    mask = 1 - ((pixel_radii / pixel_radii.max()) ** 2) * 0.5\n",
    "    mask = mask.value\n",
    "    mask[pixel_radii.value >= 0.9 * pixel_coords.Tx.max().value] = np.nan\n",
    "\n",
    "    data = (m.data - ref_map) / mask\n",
    "    \n",
    "    # imshow is mirror to m.plot\n",
    "    plt.imshow(data, origin=\"lower\", cmap=\"stereocor2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e24f6-79fb-49ef-990d-403d8c6ff36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_image(ds.images_for_date[date][20], bg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
