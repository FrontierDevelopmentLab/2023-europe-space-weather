{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf184f-2fc6-4bdc-9af7-3563fb281c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import astropy.io.fits as fits\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b7e48-7b1f-40ed-abcc-05ab074ba273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std_from_histogram(bin_edges, bin_counts):\n",
    "    # Calculate midpoints of each bin\n",
    "    bin_midpoints = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    \n",
    "    # Calculate weighted sum and total count\n",
    "    weighted_sum = np.sum(bin_midpoints * bin_counts)\n",
    "    total_count = np.sum(bin_counts)\n",
    "    \n",
    "    # Calculate mean\n",
    "    mean = weighted_sum / total_count\n",
    "    \n",
    "    # Calculate weighted squared deviation from mean\n",
    "    weighted_squared_deviation = np.sum(bin_counts * (bin_midpoints - mean)**2)\n",
    "    \n",
    "    # Calculate weighted standard deviation\n",
    "    std = np.sqrt(weighted_squared_deviation / total_count)\n",
    "    \n",
    "    return mean, std\n",
    "\n",
    "def get_dataset_counts(dataset):\n",
    "    \n",
    "    bit_depth = ds[0].flatten()[0].nbytes\n",
    "    n_vals = 2**(8*bit_depth)\n",
    "    counts = np.zeros(n_vals, dtype=np.uint64)\n",
    "\n",
    "    for d in tqdm(dataset):\n",
    "        counts += np.bincount(d.flatten(), minlength=n_vals).astype(np.uint64)\n",
    "\n",
    "    return counts\n",
    "\n",
    "\"\"\"\n",
    "counts = get_dataset_mean_std(ds)\n",
    "hist_edges = np.arange(len(counts) + 1)\n",
    "hist_counts = counts\n",
    "\n",
    "# Compute mean and standard deviation from the histogram\n",
    "mean, std = compute_mean_std_from_histogram(hist_edges, hist_counts)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a833dfae-d80c-4218-8100-25fb1fc864c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_within_time_range(events, image_paths):\n",
    "    selected_images = []\n",
    "\n",
    "    # Organize image paths by date for efficient checking\n",
    "    image_paths_by_date = {}\n",
    "    for image_path in image_paths:\n",
    "        image_date = datetime.strptime(os.path.basename(image_path).split('_')[0], '%Y%m%d').date()\n",
    "        image_paths_by_date.setdefault(image_date, []).append(image_path)\n",
    "\n",
    "    for event in events:\n",
    "\n",
    "        if not event['visible']:\n",
    "            continue\n",
    "        \n",
    "        event_start_time = datetime.strptime(event['datetime'], '%Y/%m/%d %H:%M')\n",
    "        event_stop_time = datetime.strptime(event['event_stop_time'], '%Y%m%d_%H%M%S')\n",
    "        event_date = event_start_time.date()\n",
    "        \n",
    "        # Check images within the event's date\n",
    "        if event_date in image_paths_by_date:\n",
    "\n",
    "            paths = image_paths_by_date[event_date]\n",
    "\n",
    "            next_day = event_date + timedelta(days=1)\n",
    "            if next_day in image_paths_by_date:\n",
    "                paths.extend(image_paths_by_date[next_day])\n",
    "            \n",
    "            for image_path in paths:\n",
    "                image_timestamp = datetime.strptime('_'.join(os.path.basename(image_path).split('_')[:2]), '%Y%m%d_%H%M%S')\n",
    "                if event_start_time <= image_timestamp <= event_stop_time:\n",
    "                    selected_images.append(image_path)\n",
    "\n",
    "    return selected_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e01da-63de-4071-b9d8-440e1c6fa7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMEDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root, events = [], pol='all'):\n",
    "        self.events = events\n",
    "        self.stereo_a = glob(os.path.join(root, \"*\", \"cor1\", \"stereo_a\", \"*\", \"*.fts\"))\n",
    "        self.stereo_b = glob(os.path.join(root, \"*\", \"cor1\", \"stereo_b\", \"*\", \"*.fts\"))\n",
    "\n",
    "        self.images = []\n",
    "\n",
    "        if pol == 'all':\n",
    "            self.mean = 2691.3037070368546 \n",
    "            self.std = 2579.566574917962\n",
    "            self.images.extend(self.stereo_a)\n",
    "            self.images.extend(self.stereo_b)\n",
    "        elif pol == 'sum':\n",
    "            self.images.extend([im for im in self.stereo_a if 'n4' in im])\n",
    "            self.images.extend([im for im in self.stereo_b if 'n4' in im])\n",
    "            self.mean = 3658.224788149089\n",
    "            self.std = 3399.0258091444553\n",
    "        else:\n",
    "            self.mean = 2691.3037070368546 \n",
    "            self.std = 2579.566574917962\n",
    "\n",
    "            self.images.extend([im for im in self.stereo_a if os.path.basename(os.path.dirname(im)) == pol])\n",
    "            self.images.extend([im for im in self.stereo_b if os.path.basename(os.path.dirname(im)) == pol])\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),                   # Convert image to PyTorch tensor\n",
    "            transforms.Normalize(mean=self.mean, std=self.std) # Normalize using mean and std\n",
    "        ])\n",
    "\n",
    "        self._get_labels()\n",
    "\n",
    "    def _get_labels(self):\n",
    "        self.positive_labels = set(extract_images_within_time_range(self.events['stereo_a'], self.stereo_a))\n",
    "        self.positive_labels |= set(extract_images_within_time_range(self.events['stereo_b'], self.stereo_b))\n",
    "        self.cme_images = set([im for im in self.images if im in self.positive_labels])\n",
    "                                     \n",
    "    def __getitem__(self, i):\n",
    "        raw_data = fits.getdata(self.images[i]).astype(np.float32)\n",
    "        \n",
    "        return self.transform(raw_data), (self.images[i] in self.positive_labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b67672-d73f-48dd-a12b-daafc2d29c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('events_201402.json', 'r') as fp:\n",
    "    events = json.load(fp)\n",
    "\n",
    "#events['stereo_a'] = [events['stereo_a'][10]]\n",
    "#events['stereo_b'] = [events['stereo_b'][10]]\n",
    "\n",
    "ds = CMEDataset(root=\"/media/josh/josh_tuf_a/data/fdl/2023/onboard\", pol='all', events=events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c1c692-25cf-49a9-8cb5-a3f7498be517",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds.cme_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fff406-f844-4981-bb5b-c9af66185c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds.images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
